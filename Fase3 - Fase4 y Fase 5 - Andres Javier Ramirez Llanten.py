# -*- coding: utf-8 -*-
"""Fase3 - Fase4 y Fase 5 - Andres Javier Ramirez Llanten.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/131c85j7lIeY_j2ys8fK_4blBpCnnU7fR

# **An谩lisis de gastos para la planificaci贸n financiera personal**

# **Fase 2: Entendimiento de los Datos**

### Tarea 1: Recolectar Datos Iniciales
El dataset est谩 disponible a trav茅s de Kaggle mediante el siguiente link:
https://www.kaggle.com/datasets/sumanthnimmagadda/student-spending-dataset

Los datos se encuentran en archivos de texto separados por comas (formato csv).

Por 煤ltimo descargamos el archivo en formato CSV, para validar las caracter铆sticas del dataset antes de proceder con su an谩lisis, cargamos en un Google Colab el dataset con el fin de obtener algunas estadisticas utiles con la ayuda de la libreria pandas.

## Cargar Librer铆as y Dataset
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar dataset
data_path = "https://raw.githubusercontent.com/andresr02799/DespliegueInteligenciaDatos/main/student_spending.csv"
student_spending = pd.read_csv(data_path)

# Visualizar las primeras filas
student_spending.head()

"""## Visualizaci贸n y An谩lisis de Estad铆sticas Descriptivas"""

# Generar estad铆sticas descriptivas
student_spending.describe()

"""## Descripci贸n de las columnas de los datos de h谩bitos de gasto de los estudiantes."""

print(student_spending.info())

"""## Estadisticas basicas para las columnas numericas"""

print(student_spending.describe())

"""## Estad铆sticas de resumen para columnas categ贸ricas
Recuentos 煤nicos para columnas categ贸ricas.
"""

student_spending.describe(include=['object'])

"""## Visualizar la distribuci贸n de las columnas categ贸ricas
El gr谩fico de recuento nos ayuda a comprender la distribuci贸n de las variables categ贸ricas. Por ejemplo, esto mostrar谩 si ciertos a帽os de la escuela o g茅neros est谩n m谩s representados en los datos.
"""

categorical_cols = student_spending.select_dtypes(include=['object']).columns

for col in categorical_cols:
    plt.figure(figsize=(8, 4))
    sns.countplot(x=student_spending[col])
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45)
    plt.show()

"""## **Relaci贸n entre variables categ贸ricas y num茅ricas**

Los diagramas de caja muestran c贸mo var铆an los gastos o los ingresos en distintas categor铆as (por ejemplo, g茅nero o a帽o escolar). Esto ayuda a identificar si grupos espec铆ficos tienden a tener gastos mayores o menores, ya que podemos ver c贸mo se comportan las variables num茅ricas frente a las categ贸ricas
"""

# Diagrama de caja del gasto por g茅nero
plt.figure(figsize=(10, 6))
sns.boxplot(x='gender', y='monthly_income', data=student_spending)
plt.title('Monthly Income by Gender')
plt.show()

# Diagrama de caja del gasto a lo largo del a帽o escolar
plt.figure(figsize=(10, 6))
sns.boxplot(x='year_in_school', y='tuition', data=student_spending)
plt.title('Tuition Costs by Year in School')
plt.show()

"""## Filtrar y Crear Variable gasto_no_esencial

La variable target gasto_no_esencial (que se centra en gastos en categor铆as como entretenimiento, tecnolog铆a, gastos varios y cuidado personal) permite a los estudiantes visualizar en qu茅 est谩n gastando de manera no prioritaria.
"""

# Excluir columnas y crear variable target
columnas_a_excluir = ['gender', 'year_in_school', 'major', 'preferred_payment_method']
columnas_a_excluir.append(student_spending.columns[0])  # Agrega la columna #0 a la lista
student_spending_filtrado = student_spending.drop(columns=columnas_a_excluir)
student_spending_filtrado['gasto_no_esencial'] = student_spending[['entertainment', 'personal_care', 'technology', 'miscellaneous']].sum(axis=1)

"""## Matriz de Correlaci贸n para gasto_no_esencial

Calculamos y visualizamos la correlaci贸n entre gasto_no_esencial y el resto de variables.
"""

# Matriz de correlaci贸n
corr_matrix_no_esencial = student_spending_filtrado.corr()

# Visualizar correlaci贸n con la variable target
correlacion_no_esencial = corr_matrix_no_esencial['gasto_no_esencial']
print("Correlaci贸n de cada variable con el gasto no esencial:")
print(correlacion_no_esencial)

# Heatmap de correlaci贸n
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix_no_esencial, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Matriz de Correlaci贸n - Gasto No Esencial")
plt.show()

"""Los resultados del an谩lisis de correlaci贸n indican que ciertos gastos, como tecnolog铆a y gastos varios, est谩n altamente correlacionados con el gasto_no_esencial, lo cual proporciona un punto de partida para educar a los estudiantes sobre categor铆as espec铆ficas de gasto que pueden reducir para lograr un ahorro.

## Distribuci贸n de Variables Num茅ricas (Histogramas)

Los histogramas permiten entender la distribuci贸n de cada variable, identificando si presentan sesgos.
"""

# Histogramas de todas las variables num茅ricas
student_spending_filtrado.hist(bins=15, figsize=(15, 10), edgecolor='black')
plt.suptitle("Distribuci贸n de Variables Num茅ricas")
plt.show()

"""## Diagrama de Dispersi贸n entre Ingreso Mensual y Gastos No Esenciales

Para observar la relaci贸n entre monthly_income y gasto_no_esencial.
"""

plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='monthly_income', y='gasto_no_esencial', alpha=0.6)
plt.title("Relaci贸n entre Ingreso Mensual y Gasto No Esencial")
plt.xlabel("Ingreso Mensual")
plt.ylabel("Gasto No Esencial")
plt.show()

# Crear una nueva columna 'gasto_total' que represente la suma de todos los gastos
student_spending_filtrado['gasto_total'] = student_spending[['tuition', 'housing', 'food', 'transportation', 'books_supplies',
                                                            'entertainment', 'personal_care', 'technology', 'health_wellness',
                                                            'miscellaneous']].sum(axis=1)

# Diagrama de dispersi贸n entre gasto total y gasto no esencial
plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='gasto_total', y='gasto_no_esencial', alpha=0.6)
plt.title("Relaci贸n entre Gasto Total y Gasto No Esencial")
plt.xlabel("Gasto Total")
plt.ylabel("Gasto No Esencial")
plt.show()

# Diagrama de dispersi贸n para 'technology' y 'gasto_no_esencial'
plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='technology', y='gasto_no_esencial', alpha=0.6)
plt.title("Relaci贸n entre Gasto en Tecnolog铆a y Gasto No Esencial")
plt.xlabel("Gasto en Tecnolog铆a")
plt.ylabel("Gasto No Esencial")
plt.show()

# Diagrama de dispersi贸n para 'miscellaneous' y 'gasto_no_esencial'
plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='miscellaneous', y='gasto_no_esencial', alpha=0.6)
plt.title("Relaci贸n entre Gasto en Miscel谩neos y Gasto No Esencial")
plt.xlabel("Gasto Varios")
plt.ylabel("Gasto No Esencial")
plt.show()

# Diagrama de dispersi贸n para 'entertainment' y 'gasto_no_esencial'
plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='entertainment', y='gasto_no_esencial', alpha=0.6)
plt.title("Relaci贸n entre Gasto en Entretenimiento y Gasto No Esencial")
plt.xlabel("Gasto en Entretenimiento")
plt.ylabel("Gasto No Esencial")
plt.show()

"""Con los gr谩ficos de dispersi贸n y correlaci贸n, se han identificado las categor铆as de mayor impacto en el gasto no esencial. Esto permite a la herramienta resaltar 谩reas espec铆ficas (como el gasto en tecnolog铆a y gastos varios) que pueden ser ajustadas para reducir el gasto_no_esencial.

## Boxplot de todas las variables numericas
"""

# Dibujar diagramas de caja por separado para cada columna, excluyendo la columna 'Unnamed'
columns = student_spending.drop(columns=['Unnamed: 0']).columns

plt.figure(figsize=(15, 10))  # Ajustar el tama帽o general de los gr谩ficos

for i, col in enumerate(columns, 1):
    plt.subplot(len(columns) // 3 + 1, 3, i)  # Crear una cuadr铆cula para los gr谩ficos
    sns.boxplot(data=student_spending[col])
    plt.title(col)
    plt.tight_layout()

plt.show()

"""## Boxplot de Gastos No Esenciales por Categor铆a

El boxplot ayuda a identificar outliers en cada categor铆a de gasto.
"""

plt.figure(figsize=(12, 8))
sns.boxplot(data=student_spending[['entertainment', 'personal_care', 'technology', 'miscellaneous']])
plt.title("Boxplot de Gastos No Esenciales por Categor铆a")
plt.xlabel("Categor铆a de Gasto No Esencial")
plt.ylabel("Gasto")
plt.show()

"""# **Fase 3: Preparaci贸n de Datos**

Para avanzar al modelado, debemos preparar el dataset. Las tareas incluyen eliminar valores nulos y escalar variables num茅ricas.

## 1. Tratar Valores Nulos

Eliminamos o imputamos valores nulos si es necesario.
"""

# Detectar y manejar valores nulos
student_spending_filtrado.isnull().sum()

"""## 2. Escalar Variables Num茅ricas

Usaremos MinMaxScaler para escalar las variables num茅ricas.
"""

from sklearn.preprocessing import MinMaxScaler

# Escalar variables num茅ricas
scaler = MinMaxScaler()
numerical_cols = student_spending_filtrado.select_dtypes(include=['float64', 'int64']).columns
student_spending_filtrado[numerical_cols] = scaler.fit_transform(student_spending_filtrado[numerical_cols])

"""## 3. Separar Datos de Entrenamiento y Prueba

Dividimos los datos en entrenamiento (70%) y prueba (30%).
"""

from sklearn.model_selection import train_test_split

# Variables predictoras y target
X = student_spending_filtrado.drop(columns=['gasto_no_esencial'])
y = student_spending_filtrado['gasto_no_esencial']

# Separar en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

import numpy as np

# Comprobar si hay valores infinitos o NaN en X_train y X_test
print("Valores infinitos en X_train:", np.isinf(X_train).sum().sum())
print("Valores infinitos en X_test:", np.isinf(X_test).sum().sum())
print("Valores NaN en X_train:", X_train.isna().sum().sum())
print("Valores NaN en X_test:", X_test.isna().sum().sum())

"""#**Fase 4: Modelado**

## 1. Comparacion de Modelos

Realizamos una comparacion de modelos para analizar los resultados obtenidos por cada modelo
"""

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Inicializar modelos
models = {
    "Regresi贸n Lineal": LinearRegression(),
    "rbol de Decisi贸n": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor()
}

# Entrenar y evaluar modelos
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"{name} - MSE: {mse:.4f}, R2: {r2:.4f}")

"""* Esto significa que la regresi贸n lineal predice el target (gasto_no_esencial) con una precisi贸n perfecta en el conjunto de prueba, al menos en este c谩lculo inicial. Un R虏 de 1 indica que el modelo explica el 100% de la varianza en los datos, lo que en algunos casos puede indicar sobreajuste, especialmente si el MSE es extremadamente bajo.

* El modelo de rbol de Decisi贸n tiene un R虏 de 0.8230, lo cual indica una capacidad explicativa aceptable pero significativamente inferior al modelo de regresi贸n lineal. El MSE es tambi茅n algo m谩s alto que el de la regresi贸n lineal. Los 谩rboles de decisi贸n suelen tener menor capacidad de generalizaci贸n en comparaci贸n con modelos m谩s complejos como los bosques aleatorios o modelos lineales, especialmente en datos sin mucho ruido.

* Random Forest es el modelo con el segundo mejor rendimiento en esta prueba. Aunque no alcanza el rendimiento perfecto de la regresi贸n lineal, tiene un buen R虏 (0.9372), lo que sugiere que puede generalizar bien sin caer en sobreajuste. El MSE es tambi茅n aceptablemente bajo.

## 2. Evaluacion Adicional Con Validacion Cruzada

La validaci贸n cruzada eval煤a el modelo en m煤ltiples subconjuntos del conjunto de datos, ayudando a verificar la estabilidad del modelo y su capacidad para generalizar.

* Se crea una instancia de un modelo Random Forest Regressor, sin especificar par谩metros adicionales, por lo que utiliza los valores predeterminados del modelo, como n_estimators=100 (100 谩rboles en el bosque), max_depth=None (profundidad m谩xima ilimitada para cada 谩rbol) y otros valores est谩ndar.

* X y Y: Son las variables predictoras (X) y la variable objetivo (y) del conjunto de datos. X contiene las caracter铆sticas y Y contiene el target (gasto_no_esencial).

* cv=5: Indica que se usar谩 una validaci贸n cruzada de 5 folds (subconjuntos de datos). La funci贸n divide los datos en 5 partes, utilizando 4 partes para entrenar el modelo y 1 para evaluar, y luego repite el proceso con una parte diferente como conjunto de prueba cada vez.
"""

from sklearn.model_selection import cross_val_score

# Validaci贸n cruzada para el modelo seleccionado (ej. RandomForest)
model_rf = RandomForestRegressor()
cv_scores = cross_val_score(model_rf, X, y, cv=5, scoring='r2')

print("Puntajes de validaci贸n cruzada para Random Forest (R2):", cv_scores)
print("Media de validaci贸n cruzada:", cv_scores.mean())

"""* Puntajes de validaci贸n cruzada: Los valores de R虏 en cada validaci贸n cruzada est谩n cerca de 0.95, lo que sugiere una estabilidad y precisi贸n consistentes en el Random Forest.

* Media de validaci贸n cruzada: La media de R虏 en la validaci贸n cruzada es 0.9467, lo cual confirma que el modelo es bastante estable y robusto, y que su rendimiento no depende de un solo subconjunto de los datos.


Esto reafirma que Random Forest es un modelo confiable, incluso si la Regresi贸n Lineal presenta un R虏 de 1.0 en la comparaci贸n inicial.

## 3. Ajuste de Hiperpar谩metros para el Mejor Modelo
"""

from sklearn.model_selection import GridSearchCV

# Definir el modelo y par谩metros para GridSearch
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)
grid_search.fit(X_train, y_train)

print("Mejores hiperpar谩metros:", grid_search.best_params_)
print("Mejor puntaje (R2):", grid_search.best_score_)

"""Al optimizar los hiperpar谩metros, el modelo alcanz贸 un R虏 de aproximadamente 0.9421 en la validaci贸n cruzada, que es muy cercano al valor previo, lo cual indica que la configuraci贸n predeterminada ya estaba cerca de ser 贸ptima para el modelo.

* param_grid: Es un diccionario que contiene los par谩metros a probar, como n_estimators (cantidad de 谩rboles), max_depth (profundidad m谩xima del 谩rbol) y min_samples_split (m铆nimo de muestras para dividir un nodo).

* GridSearchCV: Prueba todas las combinaciones posibles de param_grid usando validaci贸n cruzada de 5 pliegues para encontrar la configuraci贸n con mejor R虏.
* grid_search.best_params_: Muestra los hiperpar谩metros 贸ptimos seleccionados, lo que mejora la precisi贸n del modelo.

## 4. Evaluaci贸n Final del Modelo Seleccionado

Realizamos la evaluacion del modelo final seleccionado con los mejores parametros obtenidos anteriormente mediante grid_search.best_estimator_
"""

# Modelo final con los mejores par谩metros
final_model = grid_search.best_estimator_
final_model.fit(X_train, y_train)
y_pred_final = final_model.predict(X_test)

# Evaluaci贸n final
mse_final = mean_squared_error(y_test, y_pred_final)
r2_final = r2_score(y_test, y_pred_final)
print("Evaluaci贸n final - MSE:", mse_final)
print("Evaluaci贸n final - R2:", r2_final)

"""La capacidad del modelo de predecir el gasto no esencial con un R虏 de 0.9364 en el conjunto de prueba demuestra que la herramienta puede proporcionar predicciones precisas, ayudando a los estudiantes a visualizar c贸mo sus decisiones en diferentes categor铆as afectan su gasto total y sus oportunidades de ahorro.

# **Fase 5: Evaluacion**
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Explicaci贸n:
# Importamos todas las librer铆as necesarias para la evaluaci贸n de los modelos,
# incluyendo scikit-learn para los modelos y m茅tricas, y matplotlib/seaborn para visualizaci贸n.

"""Ridge y Lasso se utilizan para mitigar el sobreajuste en la regresi贸n lineal porque son t茅cnicas de regularizaci贸n, que ayudan a mejorar la capacidad de generalizaci贸n del modelo. Aqu铆 est谩 el desglose:

* **Ridge (Regularizaci贸n L2): Penalizaci贸n cuadr谩tica**
Qu茅 hace: Penaliza grandes valores de coeficientes.

  C贸mo ayuda: Mantiene todos los coeficientes peque帽os pero no los elimina por completo. Esto es 煤til si todas las variables son relevantes pero no se desea que ninguna domine excesivamente.

  Ventajas:

  Reduce el impacto de la colinealidad entre variables.
Es ideal cuando todas las variables son importantes pero el modelo es propenso al sobreajuste.


* **Lasso (Regularizaci贸n L1): Penalizaci贸n absoluta**
  Qu茅 hace: Fuerza a algunos coeficientes a ser exactamente cero.

  C贸mo ayuda: Realiza una selecci贸n de variables autom谩tica eliminando aquellas menos relevantes. Esto simplifica el modelo y lo hace menos propenso al sobreajuste.

  Ventajas:

  Ideal para datos con muchas variables, ya que selecciona autom谩ticamente las m谩s importantes.
Hace que el modelo sea m谩s interpretable al eliminar variables irrelevantes.

"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Aplicar regularizaci贸n Ridge (L2)
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X_train_scaled, y_train)
ridge_y_pred = ridge_model.predict(X_test_scaled)
ridge_mse = mean_squared_error(y_test, ridge_y_pred)
ridge_r2 = r2_score(y_test, ridge_y_pred)

print(f"Regresi贸n Ridge - MSE: {ridge_mse:.4f}, R2: {ridge_r2:.4f}")

# Aplicar regularizaci贸n Lasso (L1)
lasso_model = Lasso(alpha=0.01)
lasso_model.fit(X_train_scaled, y_train)
lasso_y_pred = lasso_model.predict(X_test_scaled)
lasso_mse = mean_squared_error(y_test, lasso_y_pred)
lasso_r2 = r2_score(y_test, lasso_y_pred)

print(f"Regresi贸n Lasso - MSE: {lasso_mse:.4f}, R2: {lasso_r2:.4f}")

# Explicaci贸n:
# Aplicamos Ridge y Lasso para mitigar el sobreajuste penalizando coeficientes grandes.
# Mostramos las m茅tricas de desempe帽o para cada variante regularizada.

"""* **Ridge (L2):**
Presenta un 2 = 1.0 y un MSE pr谩cticamente nulo, lo cual sugiere que sigue existiendo sobreajuste a pesar de la regularizaci贸n. Esto puede deberse a una baja variabilidad en los datos o a caracter铆sticas irrelevantes no penalizadas lo suficiente.

* **Lasso (L1):**
Presenta un 2 = 0.9862 y un MSE de 0.0004. Este modelo introduce penalizaci贸n en los coeficientes m谩s peque帽os, lo cual mejora la generalizaci贸n (menor tendencia al sobreajuste comparado con Ridge).
"""

ridge_coefficients = pd.Series(ridge_model.coef_, index=X.columns)
lasso_coefficients = pd.Series(lasso_model.coef_, index=X.columns)

# Gr谩fica
plt.figure(figsize=(10, 6))
ridge_coefficients.sort_values().plot(kind='bar', alpha=0.7, label="Ridge")
lasso_coefficients.sort_values().plot(kind='bar', alpha=0.7, label="Lasso", color='orange')
plt.title("Comparaci贸n de Coeficientes - Ridge vs Lasso")
plt.legend()
plt.show()

# Explicaci贸n:
# Visualizamos c贸mo Ridge y Lasso ajustan los coeficientes para reducir el sobreajuste.

"""* **Coeficientes de Ridge:**
Penaliza todos los coeficientes, pero mantiene valores m谩s altos que Lasso para algunas variables como technology y miscellaneous.

* **Coeficientes de Lasso:**
Tiende a reducir muchos coeficientes a cero, eliminando variables menos relevantes como financial_aid y transportation. Esto hace que el modelo sea m谩s interpretable y menos propenso a sobreajustarse.
"""

ridge_cv_scores = cross_val_score(ridge_model, X_train_scaled, y_train, cv=5, scoring='r2')
lasso_cv_scores = cross_val_score(lasso_model, X_train_scaled, y_train, cv=5, scoring='r2')

print(f"Ridge - R2 promedio: {ridge_cv_scores.mean():.4f}, Desviaci贸n est谩ndar: {ridge_cv_scores.std():.4f}")
print(f"Lasso - R2 promedio: {lasso_cv_scores.mean():.4f}, Desviaci贸n est谩ndar: {lasso_cv_scores.std():.4f}")

# Explicaci贸n:
# Validamos los modelos Ridge y Lasso con validaci贸n cruzada para confirmar su capacidad de generalizaci贸n.

"""* **Ridge:**
Aunque presenta un 2 = 1.0, esto podr铆a seguir reflejando sobreajuste debido a la falta de variaci贸n en los datos. La desviaci贸n est谩ndar de 0.0000 indica que su rendimiento es consistente en las distintas particiones.

* **Lasso:**
Con un 2 promedio de 0.9879 y una desviaci贸n est谩ndar de 0.0009, muestra un mejor balance entre precisi贸n y capacidad de generalizaci贸n.
"""

from sklearn.metrics import mean_squared_error, r2_score, make_scorer
from sklearn.model_selection import cross_val_score

# Comparar modelos: Ridge, Lasso, rbol de Decisi贸n, Random Forest y el mejor modelo
models = {
    "Regresi贸n Lineal": LinearRegression(),
    "rbol de Decisi贸n": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Regresi贸n Ridge": ridge_model,  # Ya entrenado
    "Regresi贸n Lasso": lasso_model,  # Ya entrenado
    "Mejor Modelo": final_model  # Modelo final con los mejores par谩metros
}

# Evaluar modelos ya entrenados y calculados
resultados = []

for name, model in models.items():
    if name in ["Regresi贸n Ridge", "Regresi贸n Lasso", "Mejor Modelo"]:  # Modelos ya entrenados
        y_pred = model.predict(X_test_scaled) if "Ridge" in name or "Lasso" in name else model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
    else:  # Modelos no regularizados (Regresi贸n Lineal, rbol de Decisi贸n, Random Forest)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

    resultados.append(f"{name} - MSE: {mse:.4f}, R2: {r2:.4f}")

# Mostrar resultados de modelos
for resultado in resultados:
    print(resultado)

# Evaluaci贸n de Ridge y Lasso con validaci贸n cruzada, calculando tambi茅n el MSE
# Crear un scorer para MSE
mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)

# Validaci贸n cruzada para Ridge
ridge_cv_mse = cross_val_score(ridge_model, X_train_scaled, y_train, cv=5, scoring=mse_scorer)
ridge_cv_r2 = cross_val_score(ridge_model, X_train_scaled, y_train, cv=5, scoring='r2')

# Validaci贸n cruzada para Lasso
lasso_cv_mse = cross_val_score(lasso_model, X_train_scaled, y_train, cv=5, scoring=mse_scorer)
lasso_cv_r2 = cross_val_score(lasso_model, X_train_scaled, y_train, cv=5, scoring='r2')

# Convertir MSE negativo a positivo
ridge_cv_mse = -ridge_cv_mse
lasso_cv_mse = -lasso_cv_mse

# Imprimir resultados de validaci贸n cruzada
print("\nValidaci贸n cruzada:")
print(f"Ridge - MSE promedio: {ridge_cv_mse.mean():.4f}, R2 promedio: {ridge_cv_r2.mean():.4f}, Desviaci贸n est谩ndar: {ridge_cv_r2.std():.4f}")
print(f"Lasso - MSE promedio: {lasso_cv_mse.mean():.4f}, R2 promedio: {lasso_cv_r2.mean():.4f}, Desviaci贸n est谩ndar: {lasso_cv_r2.std():.4f}")

"""* Regresi贸n Lineal:

  MSE: 0.0000, R虏: 1.0000
Este modelo parece haber ajustado perfectamente los datos de entrenamiento, lo que sugiere un sobreajuste. En un entorno real, esto podr铆a no generalizarse bien a nuevos datos.

* rbol de Decisi贸n:

  MSE: 0.0057, R虏: 0.8228
El desempe帽o es significativamente peor comparado con otros modelos. Aunque R虏 sugiere que el modelo explica un 82.28% de la varianza de los datos, el MSE es mayor, indicando un ajuste menos preciso.

* Random Forest:

  MSE: 0.0021, R虏: 0.9356
Este modelo logra un buen equilibrio entre precisi贸n y generalizaci贸n. Explica el 93.56% de la varianza y tiene un MSE bajo.

* Regresi贸n Ridge:

  MSE: 0.0000, R虏: 1.0000
Similar a la regresi贸n lineal, Ridge muestra un ajuste perfecto, lo cual tambi茅n sugiere sobreajuste en este caso.

* Regresi贸n Lasso:

  MSE: 0.0004, R虏: 0.9877
Lasso logra un excelente desempe帽o con un R虏 cercano a 1 y un MSE bajo, lo que indica que es un modelo preciso y probablemente menos susceptible al sobreajuste comparado con Ridge.

* Mejor Modelo:

  MSE: 0.0020, R虏: 0.9385
Este modelo parece ser una versi贸n optimizada, posiblemente una variaci贸n de Random Forest o Lasso, que logra un excelente desempe帽o al balancear precisi贸n y generalizaci贸n.

* Ridge con validacion cruzada:
  MSE promedio: 0.0000, R虏 promedio: 1.0000, Desviaci贸n est谩ndar: 0.0000
Resultados perfectos en validaci贸n cruzada sugieren que Ridge podr铆a no ser fiable en escenarios de datos reales.

* Lasso con validacion cruzada:
  MSE promedio: 0.0004, R虏 promedio: 0.9879, Desviaci贸n est谩ndar: 0.0010
Este modelo mantiene una excelente precisi贸n con variabilidad m铆nima, lo que lo hace robusto y fiable.

En el contexto de planificaci贸n financiera personal, el an谩lisis muestra que:

* La Regresi贸n Lasso parece ser la mejor opci贸n debido a su buen desempe帽o tanto en entrenamiento como en validaci贸n cruzada, mostrando robustez y generalizaci贸n.

* Aunque Ridge y la regresi贸n lineal tienen m茅tricas perfectas, esto indica un posible sobreajuste, lo que los hace menos adecuados para datos nuevos.

* Random Forest tambi茅n es una alternativa competitiva, especialmente si se busca un enfoque m谩s interpretativo (por ejemplo, identificando la importancia de las variables).

Se recomienda implementar el modelo Lasso para generar predicciones y recomendaciones personalizadas sobre h谩bitos financieros, ya que combina precisi贸n y fiabilidad con m铆nima susceptibilidad al sobreajuste.

**Pasos a seguir:**

* Validaci贸n en datos reales: Aplicar el modelo a un conjunto de datos de estudiantes reales (siguiendo normativas de privacidad) para validar su desempe帽o en un entorno real.

* Monitoreo continuo: Dise帽ar un sistema para evaluar peri贸dicamente el desempe帽o del modelo con nuevos datos, ajustando seg煤n sea necesario.

* Aumentar la cantidad de datos: Incrementar la cantidad de datos contenidos por el dataset, debido a que en este caso son solo mil datos, por lo que al incrementar la cantidad puede que varien los resultados
"""
