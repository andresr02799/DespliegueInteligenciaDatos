# -*- coding: utf-8 -*-
"""Fase3 - Fase4 y Fase 5 - Andres Javier Ramirez Llanten.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/131c85j7lIeY_j2ys8fK_4blBpCnnU7fR

# **Análisis de gastos para la planificación financiera personal**

# **Fase 2: Entendimiento de los Datos**

### Tarea 1: Recolectar Datos Iniciales
El dataset está disponible a través de Kaggle mediante el siguiente link:
https://www.kaggle.com/datasets/sumanthnimmagadda/student-spending-dataset

Los datos se encuentran en archivos de texto separados por comas (formato csv).

Por último descargamos el archivo en formato CSV, para validar las características del dataset antes de proceder con su análisis, cargamos en un Google Colab el dataset con el fin de obtener algunas estadisticas utiles con la ayuda de la libreria pandas.

## Cargar Librerías y Dataset
"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Cargar dataset
data_path = "https://raw.githubusercontent.com/andresr02799/DespliegueInteligenciaDatos/main/student_spending.csv"
student_spending = pd.read_csv(data_path)

# Visualizar las primeras filas
student_spending.head()

"""## Visualización y Análisis de Estadísticas Descriptivas"""

# Generar estadísticas descriptivas
student_spending.describe()

"""## Descripción de las columnas de los datos de hábitos de gasto de los estudiantes."""

print(student_spending.info())

"""## Estadisticas basicas para las columnas numericas"""

print(student_spending.describe())

"""## Estadísticas de resumen para columnas categóricas
Recuentos únicos para columnas categóricas.
"""

student_spending.describe(include=['object'])

"""## Visualizar la distribución de las columnas categóricas
El gráfico de recuento nos ayuda a comprender la distribución de las variables categóricas. Por ejemplo, esto mostrará si ciertos años de la escuela o géneros están más representados en los datos.
"""

categorical_cols = student_spending.select_dtypes(include=['object']).columns

for col in categorical_cols:
    plt.figure(figsize=(8, 4))
    sns.countplot(x=student_spending[col])
    plt.title(f'Distribution of {col}')
    plt.xticks(rotation=45)
    plt.show()

"""## **Relación entre variables categóricas y numéricas**

Los diagramas de caja muestran cómo varían los gastos o los ingresos en distintas categorías (por ejemplo, género o año escolar). Esto ayuda a identificar si grupos específicos tienden a tener gastos mayores o menores, ya que podemos ver cómo se comportan las variables numéricas frente a las categóricas
"""

# Diagrama de caja del gasto por género
plt.figure(figsize=(10, 6))
sns.boxplot(x='gender', y='monthly_income', data=student_spending)
plt.title('Monthly Income by Gender')
plt.show()

# Diagrama de caja del gasto a lo largo del año escolar
plt.figure(figsize=(10, 6))
sns.boxplot(x='year_in_school', y='tuition', data=student_spending)
plt.title('Tuition Costs by Year in School')
plt.show()

"""## Filtrar y Crear Variable gasto_no_esencial

La variable target gasto_no_esencial (que se centra en gastos en categorías como entretenimiento, tecnología, gastos varios y cuidado personal) permite a los estudiantes visualizar en qué están gastando de manera no prioritaria.
"""

# Excluir columnas y crear variable target
columnas_a_excluir = ['gender', 'year_in_school', 'major', 'preferred_payment_method']
columnas_a_excluir.append(student_spending.columns[0])  # Agrega la columna #0 a la lista
student_spending_filtrado = student_spending.drop(columns=columnas_a_excluir)
student_spending_filtrado['gasto_no_esencial'] = student_spending[['entertainment', 'personal_care', 'technology', 'miscellaneous']].sum(axis=1)

"""## Matriz de Correlación para gasto_no_esencial

Calculamos y visualizamos la correlación entre gasto_no_esencial y el resto de variables.
"""

# Matriz de correlación
corr_matrix_no_esencial = student_spending_filtrado.corr()

# Visualizar correlación con la variable target
correlacion_no_esencial = corr_matrix_no_esencial['gasto_no_esencial']
print("Correlación de cada variable con el gasto no esencial:")
print(correlacion_no_esencial)

# Heatmap de correlación
plt.figure(figsize=(10, 8))
sns.heatmap(corr_matrix_no_esencial, annot=True, cmap='coolwarm', linewidths=0.5)
plt.title("Matriz de Correlación - Gasto No Esencial")
plt.show()

"""Los resultados del análisis de correlación indican que ciertos gastos, como tecnología y gastos varios, están altamente correlacionados con el gasto_no_esencial, lo cual proporciona un punto de partida para educar a los estudiantes sobre categorías específicas de gasto que pueden reducir para lograr un ahorro.

## Distribución de Variables Numéricas (Histogramas)

Los histogramas permiten entender la distribución de cada variable, identificando si presentan sesgos.
"""

# Histogramas de todas las variables numéricas
student_spending_filtrado.hist(bins=15, figsize=(15, 10), edgecolor='black')
plt.suptitle("Distribución de Variables Numéricas")
plt.show()

"""## Diagrama de Dispersión entre Ingreso Mensual y Gastos No Esenciales

Para observar la relación entre monthly_income y gasto_no_esencial.
"""

plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='monthly_income', y='gasto_no_esencial', alpha=0.6)
plt.title("Relación entre Ingreso Mensual y Gasto No Esencial")
plt.xlabel("Ingreso Mensual")
plt.ylabel("Gasto No Esencial")
plt.show()

# Crear una nueva columna 'gasto_total' que represente la suma de todos los gastos
student_spending_filtrado['gasto_total'] = student_spending[['tuition', 'housing', 'food', 'transportation', 'books_supplies',
                                                            'entertainment', 'personal_care', 'technology', 'health_wellness',
                                                            'miscellaneous']].sum(axis=1)

# Diagrama de dispersión entre gasto total y gasto no esencial
plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='gasto_total', y='gasto_no_esencial', alpha=0.6)
plt.title("Relación entre Gasto Total y Gasto No Esencial")
plt.xlabel("Gasto Total")
plt.ylabel("Gasto No Esencial")
plt.show()

# Diagrama de dispersión para 'technology' y 'gasto_no_esencial'
plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='technology', y='gasto_no_esencial', alpha=0.6)
plt.title("Relación entre Gasto en Tecnología y Gasto No Esencial")
plt.xlabel("Gasto en Tecnología")
plt.ylabel("Gasto No Esencial")
plt.show()

# Diagrama de dispersión para 'miscellaneous' y 'gasto_no_esencial'
plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='miscellaneous', y='gasto_no_esencial', alpha=0.6)
plt.title("Relación entre Gasto en Misceláneos y Gasto No Esencial")
plt.xlabel("Gasto Varios")
plt.ylabel("Gasto No Esencial")
plt.show()

# Diagrama de dispersión para 'entertainment' y 'gasto_no_esencial'
plt.figure(figsize=(8, 6))
sns.scatterplot(data=student_spending_filtrado, x='entertainment', y='gasto_no_esencial', alpha=0.6)
plt.title("Relación entre Gasto en Entretenimiento y Gasto No Esencial")
plt.xlabel("Gasto en Entretenimiento")
plt.ylabel("Gasto No Esencial")
plt.show()

"""Con los gráficos de dispersión y correlación, se han identificado las categorías de mayor impacto en el gasto no esencial. Esto permite a la herramienta resaltar áreas específicas (como el gasto en tecnología y gastos varios) que pueden ser ajustadas para reducir el gasto_no_esencial.

## Boxplot de todas las variables numericas
"""

# Dibujar diagramas de caja por separado para cada columna, excluyendo la columna 'Unnamed'
columns = student_spending.drop(columns=['Unnamed: 0']).columns

plt.figure(figsize=(15, 10))  # Ajustar el tamaño general de los gráficos

for i, col in enumerate(columns, 1):
    plt.subplot(len(columns) // 3 + 1, 3, i)  # Crear una cuadrícula para los gráficos
    sns.boxplot(data=student_spending[col])
    plt.title(col)
    plt.tight_layout()

plt.show()

"""## Boxplot de Gastos No Esenciales por Categoría

El boxplot ayuda a identificar outliers en cada categoría de gasto.
"""

plt.figure(figsize=(12, 8))
sns.boxplot(data=student_spending[['entertainment', 'personal_care', 'technology', 'miscellaneous']])
plt.title("Boxplot de Gastos No Esenciales por Categoría")
plt.xlabel("Categoría de Gasto No Esencial")
plt.ylabel("Gasto")
plt.show()

"""# **Fase 3: Preparación de Datos**

Para avanzar al modelado, debemos preparar el dataset. Las tareas incluyen eliminar valores nulos y escalar variables numéricas.

## 1. Tratar Valores Nulos

Eliminamos o imputamos valores nulos si es necesario.
"""

# Detectar y manejar valores nulos
student_spending_filtrado.isnull().sum()

"""## 2. Escalar Variables Numéricas

Usaremos MinMaxScaler para escalar las variables numéricas.
"""

from sklearn.preprocessing import MinMaxScaler

# Escalar variables numéricas
scaler = MinMaxScaler()
numerical_cols = student_spending_filtrado.select_dtypes(include=['float64', 'int64']).columns
student_spending_filtrado[numerical_cols] = scaler.fit_transform(student_spending_filtrado[numerical_cols])

"""## 3. Separar Datos de Entrenamiento y Prueba

Dividimos los datos en entrenamiento (70%) y prueba (30%).
"""

from sklearn.model_selection import train_test_split

# Variables predictoras y target
X = student_spending_filtrado.drop(columns=['gasto_no_esencial'])
y = student_spending_filtrado['gasto_no_esencial']

# Separar en conjuntos de entrenamiento y prueba
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

import numpy as np

# Comprobar si hay valores infinitos o NaN en X_train y X_test
print("Valores infinitos en X_train:", np.isinf(X_train).sum().sum())
print("Valores infinitos en X_test:", np.isinf(X_test).sum().sum())
print("Valores NaN en X_train:", X_train.isna().sum().sum())
print("Valores NaN en X_test:", X_test.isna().sum().sum())

"""#**Fase 4: Modelado**

## 1. Comparacion de Modelos

Realizamos una comparacion de modelos para analizar los resultados obtenidos por cada modelo
"""

from sklearn.linear_model import LinearRegression
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score

# Inicializar modelos
models = {
    "Regresión Lineal": LinearRegression(),
    "Árbol de Decisión": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor()
}

# Entrenar y evaluar modelos
for name, model in models.items():
    model.fit(X_train, y_train)
    y_pred = model.predict(X_test)
    mse = mean_squared_error(y_test, y_pred)
    r2 = r2_score(y_test, y_pred)
    print(f"{name} - MSE: {mse:.4f}, R2: {r2:.4f}")

"""* Esto significa que la regresión lineal predice el target (gasto_no_esencial) con una precisión perfecta en el conjunto de prueba, al menos en este cálculo inicial. Un R² de 1 indica que el modelo explica el 100% de la varianza en los datos, lo que en algunos casos puede indicar sobreajuste, especialmente si el MSE es extremadamente bajo.

* El modelo de Árbol de Decisión tiene un R² de 0.8230, lo cual indica una capacidad explicativa aceptable pero significativamente inferior al modelo de regresión lineal. El MSE es también algo más alto que el de la regresión lineal. Los árboles de decisión suelen tener menor capacidad de generalización en comparación con modelos más complejos como los bosques aleatorios o modelos lineales, especialmente en datos sin mucho ruido.

* Random Forest es el modelo con el segundo mejor rendimiento en esta prueba. Aunque no alcanza el rendimiento perfecto de la regresión lineal, tiene un buen R² (0.9372), lo que sugiere que puede generalizar bien sin caer en sobreajuste. El MSE es también aceptablemente bajo.

## 2. Evaluacion Adicional Con Validacion Cruzada

La validación cruzada evalúa el modelo en múltiples subconjuntos del conjunto de datos, ayudando a verificar la estabilidad del modelo y su capacidad para generalizar.

* Se crea una instancia de un modelo Random Forest Regressor, sin especificar parámetros adicionales, por lo que utiliza los valores predeterminados del modelo, como n_estimators=100 (100 árboles en el bosque), max_depth=None (profundidad máxima ilimitada para cada árbol) y otros valores estándar.

* X y Y: Son las variables predictoras (X) y la variable objetivo (y) del conjunto de datos. X contiene las características y Y contiene el target (gasto_no_esencial).

* cv=5: Indica que se usará una validación cruzada de 5 folds (subconjuntos de datos). La función divide los datos en 5 partes, utilizando 4 partes para entrenar el modelo y 1 para evaluar, y luego repite el proceso con una parte diferente como conjunto de prueba cada vez.
"""

from sklearn.model_selection import cross_val_score

# Validación cruzada para el modelo seleccionado (ej. RandomForest)
model_rf = RandomForestRegressor()
cv_scores = cross_val_score(model_rf, X, y, cv=5, scoring='r2')

print("Puntajes de validación cruzada para Random Forest (R2):", cv_scores)
print("Media de validación cruzada:", cv_scores.mean())

"""* Puntajes de validación cruzada: Los valores de R² en cada validación cruzada están cerca de 0.95, lo que sugiere una estabilidad y precisión consistentes en el Random Forest.

* Media de validación cruzada: La media de R² en la validación cruzada es 0.9467, lo cual confirma que el modelo es bastante estable y robusto, y que su rendimiento no depende de un solo subconjunto de los datos.


Esto reafirma que Random Forest es un modelo confiable, incluso si la Regresión Lineal presenta un R² de 1.0 en la comparación inicial.

## 3. Ajuste de Hiperparámetros para el Mejor Modelo
"""

from sklearn.model_selection import GridSearchCV

# Definir el modelo y parámetros para GridSearch
param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [None, 10, 20, 30],
    'min_samples_split': [2, 5, 10]
}

grid_search = GridSearchCV(estimator=RandomForestRegressor(), param_grid=param_grid, cv=5, scoring='r2', n_jobs=-1)
grid_search.fit(X_train, y_train)

print("Mejores hiperparámetros:", grid_search.best_params_)
print("Mejor puntaje (R2):", grid_search.best_score_)

"""Al optimizar los hiperparámetros, el modelo alcanzó un R² de aproximadamente 0.9421 en la validación cruzada, que es muy cercano al valor previo, lo cual indica que la configuración predeterminada ya estaba cerca de ser óptima para el modelo.

* param_grid: Es un diccionario que contiene los parámetros a probar, como n_estimators (cantidad de árboles), max_depth (profundidad máxima del árbol) y min_samples_split (mínimo de muestras para dividir un nodo).

* GridSearchCV: Prueba todas las combinaciones posibles de param_grid usando validación cruzada de 5 pliegues para encontrar la configuración con mejor R².
* grid_search.best_params_: Muestra los hiperparámetros óptimos seleccionados, lo que mejora la precisión del modelo.

## 4. Evaluación Final del Modelo Seleccionado

Realizamos la evaluacion del modelo final seleccionado con los mejores parametros obtenidos anteriormente mediante grid_search.best_estimator_
"""

# Modelo final con los mejores parámetros
final_model = grid_search.best_estimator_
final_model.fit(X_train, y_train)
y_pred_final = final_model.predict(X_test)

# Evaluación final
mse_final = mean_squared_error(y_test, y_pred_final)
r2_final = r2_score(y_test, y_pred_final)
print("Evaluación final - MSE:", mse_final)
print("Evaluación final - R2:", r2_final)

"""La capacidad del modelo de predecir el gasto no esencial con un R² de 0.9364 en el conjunto de prueba demuestra que la herramienta puede proporcionar predicciones precisas, ayudando a los estudiantes a visualizar cómo sus decisiones en diferentes categorías afectan su gasto total y sus oportunidades de ahorro.

# **Fase 5: Evaluacion**
"""

import numpy as np
import pandas as pd
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.preprocessing import StandardScaler
import matplotlib.pyplot as plt
import seaborn as sns

# Explicación:
# Importamos todas las librerías necesarias para la evaluación de los modelos,
# incluyendo scikit-learn para los modelos y métricas, y matplotlib/seaborn para visualización.

"""Ridge y Lasso se utilizan para mitigar el sobreajuste en la regresión lineal porque son técnicas de regularización, que ayudan a mejorar la capacidad de generalización del modelo. Aquí está el desglose:

* **Ridge (Regularización L2): Penalización cuadrática**
Qué hace: Penaliza grandes valores de coeficientes.

  Cómo ayuda: Mantiene todos los coeficientes pequeños pero no los elimina por completo. Esto es útil si todas las variables son relevantes pero no se desea que ninguna domine excesivamente.

  Ventajas:

  Reduce el impacto de la colinealidad entre variables.
Es ideal cuando todas las variables son importantes pero el modelo es propenso al sobreajuste.


* **Lasso (Regularización L1): Penalización absoluta**
  Qué hace: Fuerza a algunos coeficientes a ser exactamente cero.

  Cómo ayuda: Realiza una selección de variables automática eliminando aquellas menos relevantes. Esto simplifica el modelo y lo hace menos propenso al sobreajuste.

  Ventajas:

  Ideal para datos con muchas variables, ya que selecciona automáticamente las más importantes.
Hace que el modelo sea más interpretable al eliminar variables irrelevantes.

"""

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Aplicar regularización Ridge (L2)
ridge_model = Ridge(alpha=1.0)
ridge_model.fit(X_train_scaled, y_train)
ridge_y_pred = ridge_model.predict(X_test_scaled)
ridge_mse = mean_squared_error(y_test, ridge_y_pred)
ridge_r2 = r2_score(y_test, ridge_y_pred)

print(f"Regresión Ridge - MSE: {ridge_mse:.4f}, R2: {ridge_r2:.4f}")

# Aplicar regularización Lasso (L1)
lasso_model = Lasso(alpha=0.01)
lasso_model.fit(X_train_scaled, y_train)
lasso_y_pred = lasso_model.predict(X_test_scaled)
lasso_mse = mean_squared_error(y_test, lasso_y_pred)
lasso_r2 = r2_score(y_test, lasso_y_pred)

print(f"Regresión Lasso - MSE: {lasso_mse:.4f}, R2: {lasso_r2:.4f}")

# Explicación:
# Aplicamos Ridge y Lasso para mitigar el sobreajuste penalizando coeficientes grandes.
# Mostramos las métricas de desempeño para cada variante regularizada.

"""* **Ridge (L2):**
Presenta un 𝑅2 = 1.0 y un MSE prácticamente nulo, lo cual sugiere que sigue existiendo sobreajuste a pesar de la regularización. Esto puede deberse a una baja variabilidad en los datos o a características irrelevantes no penalizadas lo suficiente.

* **Lasso (L1):**
Presenta un 𝑅2 = 0.9862 y un MSE de 0.0004. Este modelo introduce penalización en los coeficientes más pequeños, lo cual mejora la generalización (menor tendencia al sobreajuste comparado con Ridge).
"""

ridge_coefficients = pd.Series(ridge_model.coef_, index=X.columns)
lasso_coefficients = pd.Series(lasso_model.coef_, index=X.columns)

# Gráfica
plt.figure(figsize=(10, 6))
ridge_coefficients.sort_values().plot(kind='bar', alpha=0.7, label="Ridge")
lasso_coefficients.sort_values().plot(kind='bar', alpha=0.7, label="Lasso", color='orange')
plt.title("Comparación de Coeficientes - Ridge vs Lasso")
plt.legend()
plt.show()

# Explicación:
# Visualizamos cómo Ridge y Lasso ajustan los coeficientes para reducir el sobreajuste.

"""* **Coeficientes de Ridge:**
Penaliza todos los coeficientes, pero mantiene valores más altos que Lasso para algunas variables como technology y miscellaneous.

* **Coeficientes de Lasso:**
Tiende a reducir muchos coeficientes a cero, eliminando variables menos relevantes como financial_aid y transportation. Esto hace que el modelo sea más interpretable y menos propenso a sobreajustarse.
"""

ridge_cv_scores = cross_val_score(ridge_model, X_train_scaled, y_train, cv=5, scoring='r2')
lasso_cv_scores = cross_val_score(lasso_model, X_train_scaled, y_train, cv=5, scoring='r2')

print(f"Ridge - R2 promedio: {ridge_cv_scores.mean():.4f}, Desviación estándar: {ridge_cv_scores.std():.4f}")
print(f"Lasso - R2 promedio: {lasso_cv_scores.mean():.4f}, Desviación estándar: {lasso_cv_scores.std():.4f}")

# Explicación:
# Validamos los modelos Ridge y Lasso con validación cruzada para confirmar su capacidad de generalización.

"""* **Ridge:**
Aunque presenta un 𝑅2 = 1.0, esto podría seguir reflejando sobreajuste debido a la falta de variación en los datos. La desviación estándar de 0.0000 indica que su rendimiento es consistente en las distintas particiones.

* **Lasso:**
Con un 𝑅2 promedio de 0.9879 y una desviación estándar de 0.0009, muestra un mejor balance entre precisión y capacidad de generalización.
"""

from sklearn.metrics import mean_squared_error, r2_score, make_scorer
from sklearn.model_selection import cross_val_score

# Comparar modelos: Ridge, Lasso, Árbol de Decisión, Random Forest y el mejor modelo
models = {
    "Regresión Lineal": LinearRegression(),
    "Árbol de Decisión": DecisionTreeRegressor(),
    "Random Forest": RandomForestRegressor(),
    "Regresión Ridge": ridge_model,  # Ya entrenado
    "Regresión Lasso": lasso_model,  # Ya entrenado
    "Mejor Modelo": final_model  # Modelo final con los mejores parámetros
}

# Evaluar modelos ya entrenados y calculados
resultados = []

for name, model in models.items():
    if name in ["Regresión Ridge", "Regresión Lasso", "Mejor Modelo"]:  # Modelos ya entrenados
        y_pred = model.predict(X_test_scaled) if "Ridge" in name or "Lasso" in name else model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)
    else:  # Modelos no regularizados (Regresión Lineal, Árbol de Decisión, Random Forest)
        model.fit(X_train, y_train)
        y_pred = model.predict(X_test)
        mse = mean_squared_error(y_test, y_pred)
        r2 = r2_score(y_test, y_pred)

    resultados.append(f"{name} - MSE: {mse:.4f}, R2: {r2:.4f}")

# Mostrar resultados de modelos
for resultado in resultados:
    print(resultado)

# Evaluación de Ridge y Lasso con validación cruzada, calculando también el MSE
# Crear un scorer para MSE
mse_scorer = make_scorer(mean_squared_error, greater_is_better=False)

# Validación cruzada para Ridge
ridge_cv_mse = cross_val_score(ridge_model, X_train_scaled, y_train, cv=5, scoring=mse_scorer)
ridge_cv_r2 = cross_val_score(ridge_model, X_train_scaled, y_train, cv=5, scoring='r2')

# Validación cruzada para Lasso
lasso_cv_mse = cross_val_score(lasso_model, X_train_scaled, y_train, cv=5, scoring=mse_scorer)
lasso_cv_r2 = cross_val_score(lasso_model, X_train_scaled, y_train, cv=5, scoring='r2')

# Convertir MSE negativo a positivo
ridge_cv_mse = -ridge_cv_mse
lasso_cv_mse = -lasso_cv_mse

# Imprimir resultados de validación cruzada
print("\nValidación cruzada:")
print(f"Ridge - MSE promedio: {ridge_cv_mse.mean():.4f}, R2 promedio: {ridge_cv_r2.mean():.4f}, Desviación estándar: {ridge_cv_r2.std():.4f}")
print(f"Lasso - MSE promedio: {lasso_cv_mse.mean():.4f}, R2 promedio: {lasso_cv_r2.mean():.4f}, Desviación estándar: {lasso_cv_r2.std():.4f}")

"""* Regresión Lineal:

  MSE: 0.0000, R²: 1.0000
Este modelo parece haber ajustado perfectamente los datos de entrenamiento, lo que sugiere un sobreajuste. En un entorno real, esto podría no generalizarse bien a nuevos datos.

* Árbol de Decisión:

  MSE: 0.0057, R²: 0.8228
El desempeño es significativamente peor comparado con otros modelos. Aunque R² sugiere que el modelo explica un 82.28% de la varianza de los datos, el MSE es mayor, indicando un ajuste menos preciso.

* Random Forest:

  MSE: 0.0021, R²: 0.9356
Este modelo logra un buen equilibrio entre precisión y generalización. Explica el 93.56% de la varianza y tiene un MSE bajo.

* Regresión Ridge:

  MSE: 0.0000, R²: 1.0000
Similar a la regresión lineal, Ridge muestra un ajuste perfecto, lo cual también sugiere sobreajuste en este caso.

* Regresión Lasso:

  MSE: 0.0004, R²: 0.9877
Lasso logra un excelente desempeño con un R² cercano a 1 y un MSE bajo, lo que indica que es un modelo preciso y probablemente menos susceptible al sobreajuste comparado con Ridge.

* Mejor Modelo:

  MSE: 0.0020, R²: 0.9385
Este modelo parece ser una versión optimizada, posiblemente una variación de Random Forest o Lasso, que logra un excelente desempeño al balancear precisión y generalización.

* Ridge con validacion cruzada:
  MSE promedio: 0.0000, R² promedio: 1.0000, Desviación estándar: 0.0000
Resultados perfectos en validación cruzada sugieren que Ridge podría no ser fiable en escenarios de datos reales.

* Lasso con validacion cruzada:
  MSE promedio: 0.0004, R² promedio: 0.9879, Desviación estándar: 0.0010
Este modelo mantiene una excelente precisión con variabilidad mínima, lo que lo hace robusto y fiable.

En el contexto de planificación financiera personal, el análisis muestra que:

* La Regresión Lasso parece ser la mejor opción debido a su buen desempeño tanto en entrenamiento como en validación cruzada, mostrando robustez y generalización.

* Aunque Ridge y la regresión lineal tienen métricas perfectas, esto indica un posible sobreajuste, lo que los hace menos adecuados para datos nuevos.

* Random Forest también es una alternativa competitiva, especialmente si se busca un enfoque más interpretativo (por ejemplo, identificando la importancia de las variables).

Se recomienda implementar el modelo Lasso para generar predicciones y recomendaciones personalizadas sobre hábitos financieros, ya que combina precisión y fiabilidad con mínima susceptibilidad al sobreajuste.

**Pasos a seguir:**

* Validación en datos reales: Aplicar el modelo a un conjunto de datos de estudiantes reales (siguiendo normativas de privacidad) para validar su desempeño en un entorno real.

* Monitoreo continuo: Diseñar un sistema para evaluar periódicamente el desempeño del modelo con nuevos datos, ajustando según sea necesario.

* Aumentar la cantidad de datos: Incrementar la cantidad de datos contenidos por el dataset, debido a que en este caso son solo mil datos, por lo que al incrementar la cantidad puede que varien los resultados
"""
